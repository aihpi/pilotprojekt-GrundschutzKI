{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DSPy RAG Experiment\n",
        "\n",
        "Kurzer DSPy‑Durchlauf mit LiteLLM‑Proxy und dem bestehenden RAG‑Datensatz.\n",
        "\n",
        "**Voraussetzung:** `dataset` ist bereits erzeugt (z. B. aus `01_rag_baseline.ipynb`).\n",
        "Wenn nicht, lade/erzeuge ihn zuerst und führe dann dieses Notebook aus.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset erstellen (CSV + Qdrant)\n",
        "\n",
        "Lädt Fragen/Antworten aus der CSV, holt Kontexte aus Qdrant und erzeugt ein `dataset`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "14a0082d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/felixboelter/Documents/GitHub/pilotprojekt-GrundschutzKI/notebooks/litellm_client.py:177: UserWarning: Api key is used with an insecure connection.\n",
            "  return QdrantClient(url=url, api_key=cfg.api_key)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n",
            "Processing embeddings 0 to 1 / 1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'contexts', 'ground_truth'],\n",
              "    num_rows: 42\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datasets import Dataset\n",
        "from litellm_client import (\n",
        "    load_llm_config,\n",
        "    load_vectordb_config,\n",
        "    get_qdrant_client,\n",
        "    get_embeddings,\n",
        ")\n",
        "\n",
        "def _retrieve_contexts(question: str, k: int, client, collection_name: str, llm_cfg):\n",
        "    query_emb = get_embeddings([question], llm_cfg, batch_size=1)[0]\n",
        "    results = client.query_points(\n",
        "        collection_name=collection_name,\n",
        "        query=query_emb,\n",
        "        limit=k,\n",
        "    ).points\n",
        "    return [res.payload.get('text', '') for res in results]\n",
        "\n",
        "def build_eval_dataset(\n",
        "    csv_path: str = '../GrundschutzKI_Fragen-Antworten-Fundstellen.csv',\n",
        "    top_k: int = 5,\n",
        ") -> Dataset:\n",
        "    llm_cfg = load_llm_config()\n",
        "    vec_cfg = load_vectordb_config()\n",
        "    qdrant_client = get_qdrant_client(vec_cfg)\n",
        "    collection_name = vec_cfg.collection or 'grundschutz_xml'\n",
        "\n",
        "    df = pd.read_csv(Path(csv_path), sep=';', encoding='utf-8-sig')\n",
        "    records = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        question = row['Frage']\n",
        "        ground_truth = row['Antwort']\n",
        "        contexts = _retrieve_contexts(question, top_k, qdrant_client, collection_name, llm_cfg)\n",
        "\n",
        "        records.append({\n",
        "            'question': question,\n",
        "            'contexts': contexts,\n",
        "            'ground_truth': ground_truth,\n",
        "        })\n",
        "\n",
        "    return Dataset.from_list(records)\n",
        "\n",
        "dataset = build_eval_dataset(top_k=5)\n",
        "dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dspy\n",
        "from litellm_client import load_llm_config\n",
        "\n",
        "llm_cfg = load_llm_config()\n",
        "\n",
        "# LiteLLM‑Proxy (OpenAI‑kompatibel)\n",
        "dspy_llm = dspy.LM(\n",
        "    model=llm_cfg.model,\n",
        "    api_base=llm_cfg.api_base,\n",
        "    api_key=llm_cfg.api_key,\n",
        "    temperature=0.2,\n",
        ")\n",
        "\n",
        "dspy.configure(lm=dspy_llm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RAGAnswer(dspy.Signature):\n",
        "    \"\"\"Answer using only the provided context.\"\"\"\n",
        "    question: str = dspy.InputField()\n",
        "    context: str = dspy.InputField()\n",
        "    response: str = dspy.OutputField(desc=\"Antwort auf Deutsch, kurz und präzise, maximal 2–3 Sätze.\")\n",
        "\n",
        "class RAGModule(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.predict = dspy.Predict(\n",
        "            RAGAnswer,\n",
        "            instructions=\"Antworte auf Deutsch, kurz und präzise, max. 2–3 Sätze. Nutze nur den Kontext.\",\n",
        "        )\n",
        "\n",
        "    def forward(self, question, context):\n",
        "        return self.predict(question=question, context=context)\n",
        "\n",
        "rag = RAGModule()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- SAMPLE 0 ---\n",
            "QUESTION: Was ist der Unterschied zwischen Prozess- und Systembausteinen?\n",
            "PREDICTED ANSWER: Prozess‑Bausteine beschreiben sicherheitsrelevante Vorgänge, organisatorische und betriebliche Maßnahmen und gelten in der Regel für den gesamten Informationsverbund oder große Teile davon. System‑Bausteine hingegen werden auf konkrete Zielobjekte wie Anwendungen, IT‑Systeme, Geräte oder Gebäude angewendet und behandeln deren spezifische Sicherheitsaspekte.\n",
            "GROUND TRUTH: Prozess-Bausteine gelten in der Regel für sämtliche oder große Teile des Informationsverbunds gleichermaßen, System-Bausteine lassen sich in der Regel auf einzelne Objekte oder Gruppen von Objekten anwenden. Die Prozess- und System-Bausteine bestehen wiederum aus weiteren Teilschichten. In den Hinweisen zum Schichtenmodell und zur Modellierung wird beschrieben, wann ein einzelner Baustein sinnvollerweise eingesetzt werden soll und auf welche Zielobjekte er anzuwenden ist. \n",
            "\n",
            "--- SAMPLE 1 ---\n",
            "QUESTION: Welche grundlegenden Sicherheitsmaßnahmen müssen beim Einrichten eines Webservers ergriffen werden?\n",
            "PREDICTED ANSWER: Beim Aufsetzen eines Webservers muss zunächst eine sichere Grundkonfiguration erfolgen: Der Serverprozess läuft unter einem Konto mit minimalen Rechten in einer gekapselten Umgebung, nicht benötigte Module und Schreibrechte werden deaktiviert, und nur das definierte WWW‑Wurzelverzeichnis wird freigegeben. Zusätzlich sind restriktive HTTP‑Header (Strict‑Transport‑Security, Content‑Type, X‑Content‑Type‑Options, Cache‑Control) zu setzen, Cookies mit den Attributen Secure, SameSite und HttpOnly zu versehen, alle Zugriffe zu protokollieren und regelmäßig Penetrationstests sowie Revisionen durchzuführen. Bei erhöhtem Schutzbedarf sollte zudem eine Web‑Application‑Firewall eingesetzt und Datei‑Uploads vor Veröffentlichung auf Schadsoftware geprüft werden.\n",
            "GROUND TRUTH: Nach der Installation eines Webservers muss eine sichere Grundkonfiguration vorgenommen werden. Dazu gehört die Zuweisung des Webserver-Prozesses einem Konto mit minimalen Rechten, die Ausführung in einer gekapselten Umgebung (sofern unterstützt), sowie die Deaktivierung nicht benötigter Module und Funktionen. Ist eine gekapselte Umgebung nicht möglich, sollte jeder Webserver auf einem eigenen physischen oder virtuellen Server laufen. Dem Webserver-Dienst MÜSSEN alle nicht notwendige Schreibberechtigungen entzogen werden. Nicht benötigte Module und Funktionen des Webservers MÜSSEN deaktiviert werden.\n",
            "\n",
            "--- SAMPLE 2 ---\n",
            "QUESTION: Wie müssen Webserver-Dateien geschützt werden?\n",
            "PREDICTED ANSWER: Der IT‑Betrieb muss alle Webserver‑Dateien (insbesondere Skripte und Konfigurationsdateien) so absichern, dass weder unbefugtes Lesen noch Änderungen möglich sind. Der Webserver ist so zu konfigurieren, dass nur das definierte WWW‑Wurzelverzeichnis bedient wird, Verzeichnislisten deaktiviert sind und vertrauliche Dateien nicht in öffentlichen Verzeichnissen liegen; regelmäßige Kontrollen sind erforderlich.\n",
            "GROUND TRUTH: Alle Dateien auf dem Webserver, insbesondere Skripte und Konfigurationsdateien, müssen so geschützt werden, dass sie nicht unbefugt gelesen oder verändert werden können. Der Webserver muss so konfiguriert sein, dass er nur Dateien aus dem definierten WWW-Wurzelverzeichnis ausliefert. Nicht benötigte Funktionen zur Verzeichnisaufzählung müssen deaktiviert werden, und vertrauliche Daten dürfen nicht in öffentlichen Verzeichnissen gespeichert werden. Regelmäßige Überprüfungen sind erforderlich.\n"
          ]
        }
      ],
      "source": [
        "# Beispielausgaben\n",
        "for i in range(3):\n",
        "    row = dataset[i]\n",
        "    context = \"\\n\\n\".join(row[\"contexts\"])\n",
        "    pred = rag(question=row[\"question\"], context=context)\n",
        "    print(f\"\\n--- SAMPLE {i} ---\")\n",
        "    print(\"QUESTION:\", row[\"question\"])\n",
        "    print(\"PREDICTED ANSWER:\", pred.response)\n",
        "    print(\"GROUND TRUTH:\", row[\"ground_truth\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DSPy Optimizer (MIPROv2)\n",
        "\n",
        "Optimiert die Prompt‑Instruktionen für das RAG‑Programm. Kann kostenintensiv sein.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7497c6f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from ragas.metrics.collections import AnswerCorrectness\n",
        "from ragas.embeddings.litellm_provider import LiteLLMEmbeddings\n",
        "from ragas.llms import llm_factory\n",
        "import instructor, litellm\n",
        "\n",
        "# RAGAS LLM\n",
        "litellm.api_base = llm_cfg.api_base\n",
        "litellm.api_key = llm_cfg.api_key\n",
        "client = instructor.from_litellm(litellm.acompletion, mode=instructor.Mode.MD_JSON)\n",
        "ragas_llm = llm_factory(llm_cfg.model, client=client, adapter=\"litellm\", model_args={\"temperature\": 0.2})\n",
        "\n",
        "# Embeddings (für Similarity)\n",
        "embeddings = LiteLLMEmbeddings(\n",
        "    model=llm_cfg.embedding_model,\n",
        "    api_key=llm_cfg.api_key,\n",
        "    api_base=llm_cfg.api_base,\n",
        "    encoding_format=\"float\",\n",
        ")\n",
        "\n",
        "ac = AnswerCorrectness(llm=ragas_llm, embeddings=embeddings)\n",
        "\n",
        "def ragas_ac_metric(example, pred):\n",
        "    return asyncio.run(ac.ascore(\n",
        "        user_input=example.question,\n",
        "        response=pred.response,\n",
        "        reference=example.response,\n",
        "    ))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/29 11:37:18 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
            "num_trials: 10\n",
            "minibatch: False\n",
            "num_fewshot_candidates: 6\n",
            "num_instruct_candidates: 3\n",
            "valset size: 6\n",
            "\n",
            "2026/01/29 11:37:18 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
            "2026/01/29 11:37:18 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
            "\n",
            "2026/01/29 11:37:18 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=6 sets of demonstrations...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapping set 1/6\n",
            "Bootstrapping set 2/6\n",
            "Bootstrapping set 3/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:16<00:00,  8.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 4/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 13.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 5/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1/2 [00:00<00:00, 22.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Bootstrapping set 6/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1/2 [00:00<00:00, 23.78it/s]\n",
            "2026/01/29 11:37:35 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
            "2026/01/29 11:37:35 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
            "2026/01/29 11:37:35 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "Proposing N=3 instructions...\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/29 11:38:03 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
            "\n",
            "2026/01/29 11:38:03 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Answer using only the provided context.\n",
            "\n",
            "2026/01/29 11:38:03 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Formuliere eine **kurze** (maximal 2 – 3 Sätze) **präzise** Antwort **auf Deutsch**, die **ausschließlich** die im bereitgestellten Kontext enthaltene Anforderung wiedergibt. Nutze die dort vorkommenden **normativen Formulierungen** (z. B. „MUSS“, „SOLLTEN“, „DÜRFEN“) und **verzichte** auf Zitate von Abschnitts‑ oder Bausteinnummern, Tabellen oder anderen Metadaten. Gib **nur** die relevante Anforderung wieder, ohne zusätzliche Erläuterungen oder eigene Inhalte.\n",
            "\n",
            "2026/01/29 11:38:03 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Antworte **ausschließlich** auf Basis des angegebenen Kontextes und **nur** in deutscher Sprache. Formuliere die Antwort **präzise und kompakt**: maximal **zwei‑bis‑drei Sätze**, wobei du die zentrale Anforderung oder Information aus dem Kontext wiedergeben sollst, **ohne Zitate, Abschnitts‑ oder Quellenangaben**. Verwende, wenn im Kontext vorhanden, die dortige **normative Formulierung** (z. B. „MUSS“, „SOLLTEN“, „DÜRFEN“) und stelle sicher, dass die Antwort **kurz, eindeutig und ausschließlich aus dem bereitgestellten Text** abgeleitet ist.\n",
            "\n",
            "2026/01/29 11:38:03 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2026/01/29 11:38:03 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
            "2026/01/29 11:38:03 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
            "\n",
            "2026/01/29 11:38:03 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 10 - Full Evaluation of Default Program ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 4.62 / 6 (77.1%): 100%|██████████| 6/6 [00:12<00:00,  2.08s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/29 11:38:16 INFO dspy.evaluate.evaluate: Average Metric: 4.623809523809523 / 6 (77.1%)\n",
            "2026/01/29 11:38:16 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 77.06\n",
            "\n",
            "/Users/felixboelter/Documents/GitHub/pilotprojekt-GrundschutzKI/.venv/lib/python3.12/site-packages/dspy/teleprompt/mipro_optimizer_v2.py:646: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
            "  sampler = optuna.samplers.TPESampler(seed=seed, multivariate=True)\n",
            "2026/01/29 11:38:16 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 10 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 4.66 / 6 (77.7%): 100%|██████████| 6/6 [00:18<00:00,  3.07s/it] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/29 11:38:34 INFO dspy.evaluate.evaluate: Average Metric: 4.663216321632163 / 6 (77.7%)\n",
            "2026/01/29 11:38:34 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 77.72\n",
            "2026/01/29 11:38:34 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 77.72 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 3'].\n",
            "2026/01/29 11:38:34 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [77.06, 77.72]\n",
            "2026/01/29 11:38:34 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 77.72\n",
            "2026/01/29 11:38:34 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2026/01/29 11:38:34 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 10 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 4.70 / 6 (78.3%): 100%|██████████| 6/6 [00:14<00:00,  2.39s/it] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/29 11:38:48 INFO dspy.evaluate.evaluate: Average Metric: 4.700757575757576 / 6 (78.3%)\n",
            "2026/01/29 11:38:48 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 78.35\n",
            "2026/01/29 11:38:48 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 78.35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 0'].\n",
            "2026/01/29 11:38:48 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [77.06, 77.72, 78.35]\n",
            "2026/01/29 11:38:48 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 78.35\n",
            "2026/01/29 11:38:48 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2026/01/29 11:38:48 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 10 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 4.66 / 6 (77.7%): 100%|██████████| 6/6 [00:00<00:00, 1712.78it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/29 11:38:49 INFO dspy.evaluate.evaluate: Average Metric: 4.663216321632163 / 6 (77.7%)\n",
            "2026/01/29 11:38:49 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 77.72 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 5'].\n",
            "2026/01/29 11:38:49 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [77.06, 77.72, 78.35, 77.72]\n",
            "2026/01/29 11:38:49 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 78.35\n",
            "2026/01/29 11:38:49 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2026/01/29 11:38:49 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 10 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 4.74 / 6 (79.0%): 100%|██████████| 6/6 [00:17<00:00,  2.97s/it] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/29 11:39:06 INFO dspy.evaluate.evaluate: Average Metric: 4.742424242424242 / 6 (79.0%)\n",
            "2026/01/29 11:39:06 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 79.04\n",
            "2026/01/29 11:39:06 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 79.04 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 2'].\n",
            "2026/01/29 11:39:06 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [77.06, 77.72, 78.35, 77.72, 79.04]\n",
            "2026/01/29 11:39:06 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 79.04\n",
            "2026/01/29 11:39:06 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2026/01/29 11:39:06 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 10 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 4.79 / 6 (79.8%): 100%|██████████| 6/6 [00:16<00:00,  2.79s/it] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/29 11:39:23 INFO dspy.evaluate.evaluate: Average Metric: 4.79047619047619 / 6 (79.8%)\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 79.84\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 79.84 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5'].\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [77.06, 77.72, 78.35, 77.72, 79.04, 79.84]\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 79.84\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 10 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 4.70 / 6 (78.3%): 100%|██████████| 6/6 [00:00<00:00, 3361.27it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/29 11:39:23 INFO dspy.evaluate.evaluate: Average Metric: 4.700757575757576 / 6 (78.3%)\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 78.35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 0'].\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [77.06, 77.72, 78.35, 77.72, 79.04, 79.84, 78.35]\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 79.84\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 10 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 4.74 / 6 (79.0%): 100%|██████████| 6/6 [00:00<00:00, 625.92it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/29 11:39:23 INFO dspy.evaluate.evaluate: Average Metric: 4.742424242424242 / 6 (79.0%)\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 79.04 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5'].\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [77.06, 77.72, 78.35, 77.72, 79.04, 79.84, 78.35, 79.04]\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 79.84\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 10 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 4.66 / 6 (77.7%): 100%|██████████| 6/6 [00:00<00:00, 1926.79it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/29 11:39:23 INFO dspy.evaluate.evaluate: Average Metric: 4.663216321632163 / 6 (77.7%)\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 77.72 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4'].\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [77.06, 77.72, 78.35, 77.72, 79.04, 79.84, 78.35, 79.04, 77.72]\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 79.84\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 10 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 4.74 / 6 (79.0%): 100%|██████████| 6/6 [00:00<00:00, 3005.95it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/29 11:39:23 INFO dspy.evaluate.evaluate: Average Metric: 4.742424242424242 / 6 (79.0%)\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 79.04 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5'].\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [77.06, 77.72, 78.35, 77.72, 79.04, 79.84, 78.35, 79.04, 77.72, 79.04]\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 79.84\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 10 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 4.79 / 6 (79.8%): 100%|██████████| 6/6 [00:00<00:00, 3327.49it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/29 11:39:23 INFO dspy.evaluate.evaluate: Average Metric: 4.79047619047619 / 6 (79.8%)\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 79.84 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5'].\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [77.06, 77.72, 78.35, 77.72, 79.04, 79.84, 78.35, 79.04, 77.72, 79.04, 79.84]\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 79.84\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2026/01/29 11:39:23 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 79.84!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import dspy\n",
        "from dspy.evaluate import SemanticF1\n",
        "\n",
        "# DSPy Examples aus dem vorhandenen Dataset\n",
        "examples = []\n",
        "for row in dataset:\n",
        "    context = \"\\n\\n\".join(row[\"contexts\"])\n",
        "    examples.append(\n",
        "        dspy.Example(question=row[\"question\"], context=context, response=row[\"ground_truth\"])\n",
        "            .with_inputs(\"question\", \"context\")\n",
        "    )\n",
        "\n",
        "\n",
        "# einfache Splits\n",
        "trainset = examples[: max(1, len(examples)//5)]\n",
        "devset = examples[max(1, len(examples)//5):]\n",
        "\n",
        "# metric = SemanticF1(decompositional=True)\n",
        "\n",
        "# Optimizer (wenig Threads zum Start)\n",
        "tp = dspy.MIPROv2(metric=ragas_ac_metric, auto='light', num_threads=4)\n",
        "optimized_rag = tp.compile(rag, trainset=trainset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "aeab95dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "split = max(1, len(dataset) // 5)\n",
        "dev_rows = list(dataset)[split:]\n",
        "dspy_dev_answers = []\n",
        "for row in dev_rows:\n",
        "    context = \"\\n\\n\".join(row[\"contexts\"])\n",
        "    pred = optimized_rag(question=row[\"question\"], context=context)\n",
        "    dspy_dev_answers.append(pred.response)\n",
        "\n",
        "# Neues Dataset fürs Scoring\n",
        "from datasets import Dataset\n",
        "\n",
        "dev_dataset = Dataset.from_dict({\n",
        "    \"question\": [r[\"question\"] for r in dev_rows],\n",
        "    \"contexts\": [r[\"contexts\"] for r in dev_rows],\n",
        "    \"ground_truth\": [r[\"ground_truth\"] for r in dev_rows],\n",
        "    \"answer\": dspy_dev_answers,   # <- DSPy Antworten\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAGAS Evaluation (DSPy Answers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'context_precision': {'avg': 0.9203022875520346, 'min': 0.4499999999775, 'max': 0.99999999998}, 'context_recall': {'avg': 0.9509803921568628, 'min': 0.5, 'max': 1.0}, 'faithfulness': {'avg': 0.6060677884207296, 'min': 0.0, 'max': 1.0}, 'answer_correctness': {'avg': 0.5572924247809161, 'min': 0.12253877440565702, 'max': 0.9855250378946347}}\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from ragas.llms import llm_factory\n",
        "from ragas.embeddings.litellm_provider import LiteLLMEmbeddings\n",
        "from ragas.metrics.collections import ContextPrecision, ContextRecall, Faithfulness, AnswerCorrectness\n",
        "import instructor\n",
        "import litellm\n",
        "\n",
        "# RAGAS LLM (LiteLLM proxy)\n",
        "litellm.api_base = llm_cfg.api_base\n",
        "litellm.api_key = llm_cfg.api_key\n",
        "client = instructor.from_litellm(litellm.acompletion, mode=instructor.Mode.MD_JSON)\n",
        "ragas_llm = llm_factory(llm_cfg.model, client=client, adapter='litellm', model_args={'temperature': 0.2})\n",
        "\n",
        "embeddings = LiteLLMEmbeddings(\n",
        "    model=llm_cfg.embedding_model,\n",
        "    api_key=llm_cfg.api_key,\n",
        "    api_base=llm_cfg.api_base,\n",
        "    encoding_format='float',\n",
        ")\n",
        "\n",
        "scorers = {\n",
        "    'context_precision': ContextPrecision(llm=ragas_llm),\n",
        "    'context_recall': ContextRecall(llm=ragas_llm),\n",
        "    'faithfulness': Faithfulness(llm=ragas_llm),\n",
        "    'answer_correctness': AnswerCorrectness(llm=ragas_llm, embeddings=embeddings),\n",
        "}\n",
        "\n",
        "async def _score_row(row, sem):\n",
        "    async with sem:\n",
        "        return {\n",
        "            'context_precision': (await scorers['context_precision'].ascore(\n",
        "                user_input=row['question'],\n",
        "                reference=row['ground_truth'],\n",
        "                retrieved_contexts=row['contexts'],\n",
        "            )).value,\n",
        "            'context_recall': (await scorers['context_recall'].ascore(\n",
        "                user_input=row['question'],\n",
        "                reference=row['ground_truth'],\n",
        "                retrieved_contexts=row['contexts'],\n",
        "            )).value,\n",
        "            'faithfulness': (await scorers['faithfulness'].ascore(\n",
        "                user_input=row['question'],\n",
        "                response=row['answer'],\n",
        "                retrieved_contexts=row['contexts'],\n",
        "            )).value,\n",
        "            'answer_correctness': (await scorers['answer_correctness'].ascore(\n",
        "                user_input=row['question'],\n",
        "                response=row['answer'],\n",
        "                reference=row['ground_truth'],\n",
        "            )).value,\n",
        "        }\n",
        "\n",
        "async def score_dataset_batched(ds, batch_size=10, concurrency=5):\n",
        "    sem = asyncio.Semaphore(concurrency)\n",
        "    rows = list(ds)\n",
        "    results = []\n",
        "    for i in range(0, len(rows), batch_size):\n",
        "        batch = rows[i : i + batch_size]\n",
        "        tasks = [asyncio.create_task(_score_row(r, sem)) for r in batch]\n",
        "        results.extend(await asyncio.gather(*tasks))\n",
        "    return results\n",
        "\n",
        "scores = await score_dataset_batched(dev_dataset, batch_size=16, concurrency=10)\n",
        "stats = {\n",
        "    k: {\n",
        "        'avg': sum(s[k] for s in scores) / len(scores),\n",
        "        'min': min(s[k] for s in scores),\n",
        "        'max': max(s[k] for s in scores),\n",
        "    }\n",
        "    for k in scores[0].keys()\n",
        "}\n",
        "print(stats)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ergebnis-DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>answer_dspy</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Was ist bei der Auswahl eines externen Webhost...</td>\n",
              "      <td>gement (B)\\nFür Prozesse, die potenziell ausge...</td>\n",
              "      <td>Bei der Auswahl eines externen Webhosters muss...</td>\n",
              "      <td>Bei der Nutzung externer Webhosting-Dienste so...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.981953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wie sollten Fehlermeldungen auf einem Webserve...</td>\n",
              "      <td>lständig dargestellt oder Sicherheitsmechanism...</td>\n",
              "      <td>Fehlermeldungen dürfen weder Produkt‑ noch Ver...</td>\n",
              "      <td>Aus HTTP-Antworten und Fehlermeldungen dürfen ...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.951677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Welche Maßnahmen sind bei erhöhtem Schutzbedar...</td>\n",
              "      <td>\\n...\\n\\nStrict-Transport-Security,\\n\\n...\\n\\n...</td>\n",
              "      <td>Bei erhöhtem Schutzbedarf sollten Sie eine Web...</td>\n",
              "      <td>Bei erhöhtem Schutzbedarf sollten Webserver re...</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.506447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wer trägt die Verantwortung für Informationssi...</td>\n",
              "      <td>rungskatalog Cloud Computing (C5)“ Kriterien z...</td>\n",
              "      <td>Die Verantwortung für die Informationssicherhe...</td>\n",
              "      <td>Die Verantwortung für Informationssicherheit v...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.722545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Welche Prozesse dürfen grundsätzlich ausgelage...</td>\n",
              "      <td>gement (B)\\nFür Prozesse, die potenziell ausge...</td>\n",
              "      <td>Grundsätzlich dürfen nur solche Prozesse ausge...</td>\n",
              "      <td>Nur Prozesse, die risikoorientiert bewertet wu...</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.967802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  Was ist bei der Auswahl eines externen Webhost...   \n",
              "1  Wie sollten Fehlermeldungen auf einem Webserve...   \n",
              "2  Welche Maßnahmen sind bei erhöhtem Schutzbedar...   \n",
              "3  Wer trägt die Verantwortung für Informationssi...   \n",
              "4  Welche Prozesse dürfen grundsätzlich ausgelage...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  gement (B)\\nFür Prozesse, die potenziell ausge...   \n",
              "1  lständig dargestellt oder Sicherheitsmechanism...   \n",
              "2  \\n...\\n\\nStrict-Transport-Security,\\n\\n...\\n\\n...   \n",
              "3  rungskatalog Cloud Computing (C5)“ Kriterien z...   \n",
              "4  gement (B)\\nFür Prozesse, die potenziell ausge...   \n",
              "\n",
              "                                         answer_dspy  \\\n",
              "0  Bei der Auswahl eines externen Webhosters muss...   \n",
              "1  Fehlermeldungen dürfen weder Produkt‑ noch Ver...   \n",
              "2  Bei erhöhtem Schutzbedarf sollten Sie eine Web...   \n",
              "3  Die Verantwortung für die Informationssicherhe...   \n",
              "4  Grundsätzlich dürfen nur solche Prozesse ausge...   \n",
              "\n",
              "                                        ground_truth  context_precision  \\\n",
              "0  Bei der Nutzung externer Webhosting-Dienste so...           1.000000   \n",
              "1  Aus HTTP-Antworten und Fehlermeldungen dürfen ...           0.500000   \n",
              "2  Bei erhöhtem Schutzbedarf sollten Webserver re...           0.450000   \n",
              "3  Die Verantwortung für Informationssicherheit v...           1.000000   \n",
              "4  Nur Prozesse, die risikoorientiert bewertet wu...           0.804167   \n",
              "\n",
              "   context_recall  faithfulness  answer_correctness  \n",
              "0             1.0           0.0            0.981953  \n",
              "1             1.0           1.0            0.951677  \n",
              "2             1.0           1.0            0.506447  \n",
              "3             1.0           1.0            0.722545  \n",
              "4             1.0           0.0            0.967802  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# DSPy-Antworten erzeugen (optimized_rag falls vorhanden)\n",
        "_rag_model = optimized_rag if 'optimized_rag' in globals() else rag\n",
        "dspy_answers = []\n",
        "for row in dataset:\n",
        "    context = \"\\n\\n\".join(row['contexts'])\n",
        "    pred = _rag_model(question=row['question'], context=context)\n",
        "    dspy_answers.append(pred.response)\n",
        "\n",
        "\n",
        "# DataFrame zusammenbauen\n",
        "df = pd.DataFrame({\n",
        "    'question': [r['question'] for r in dev_dataset],\n",
        "    'contexts': [\"\\n\\n\".join(r['contexts']) for r in dev_dataset],\n",
        "    'answer_dspy': dspy_dev_answers,\n",
        "    'ground_truth': [r['ground_truth'] for r in dev_dataset],\n",
        "    'context_precision': [s['context_precision'] for s in scores],\n",
        "    'context_recall': [s['context_recall'] for s in scores],\n",
        "    'faithfulness': [s['faithfulness'] for s in scores],\n",
        "    'answer_correctness': [s['answer_correctness'] for s in scores],\n",
        "})\n",
        "\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe4068e9",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pilotprojekt-grundschutzki",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
