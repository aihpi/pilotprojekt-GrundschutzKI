{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed67689",
   "metadata": {},
   "source": [
    "## Import the Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e72dd16",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(PROJECT_ROOT / \u001b[33m\"\u001b[39m\u001b[33mnotebooks\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys.path:\n\u001b[32m     11\u001b[39m     sys.path.insert(\u001b[32m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(PROJECT_ROOT / \u001b[33m\"\u001b[39m\u001b[33mnotebooks\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrun_evaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generate_evaluation_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Pilotprojekte/pilotprojekt-GrundschutzKI/scripts/run_evaluation.py:33\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, List, Optional\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Ensure notebooks/ is importable for litellm_client\u001b[39;00m\n\u001b[32m     36\u001b[39m SCRIPT_DIR = Path(\u001b[34m__file__\u001b[39m).parent.resolve()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path for imports\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == \"notebooks\" else NOTEBOOK_DIR\n",
    "\n",
    "if str(PROJECT_ROOT / \"scripts\") not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT / \"scripts\"))\n",
    "if str(PROJECT_ROOT / \"notebooks\") not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT / \"notebooks\"))\n",
    "\n",
    "from run_evaluation import generate_evaluation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db31be0",
   "metadata": {},
   "source": [
    "## Function Parameters\n",
    "\n",
    "The `generate_evaluation_results()` function requires the following parameters:\n",
    "\n",
    "### Required Parameters\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "|-----------|------|-------------|\n",
    "| `llm` | str | LLM model identifier (e.g., `\"openai/gpt-oss-120b\"`) |\n",
    "| `embedding_model` | str | Embedding model identifier (e.g., `\"openai/octen-embedding-8b\"`) |\n",
    "| `input_data_description` | str | Free-text description of input data and preprocessing |\n",
    "| `chunk_size` | int | Character size of chunks in vector database |\n",
    "| `chunk_overlap` | int | Character overlap between chunks |\n",
    "| `top_k` | int | Number of chunks to retrieve per question |\n",
    "| `output_name` | str | Base name for output files (without extension) |\n",
    "| `temperature` | float | LLM temperature setting |\n",
    "\n",
    "### Optional Parameters (with defaults)\n",
    "\n",
    "| Parameter | Type | Default | Description |\n",
    "|-----------|------|---------|-------------|\n",
    "| `seed` | int | 42 | Random seed for reproducibility |\n",
    "| `eval_csv_path` | str | `\"data/data_evaluation/GSKI_Fragen-Antworten-Fundstellen.csv\"` | Path to evaluation CSV |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad33487",
   "metadata": {},
   "source": [
    "## Example: XML Kompendium with GPT-OSS-120B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation with XML Kompendium data\n",
    "csv_path = generate_evaluation_results(\n",
    "    # Required parameters\n",
    "    llm=\"openai/gpt-oss-120b\",\n",
    "    embedding_model=\"openai/octen-embedding-8b\",\n",
    "    input_data_description=\"XML Kompendium 2023 (data/grundschutz.xml), character-based chunking with 4000 char chunks and 200 char overlap\",\n",
    "    chunk_size=4000,\n",
    "    chunk_overlap=200,\n",
    "    top_k=5,\n",
    "    output_name=\"gpt-oss-120b_kompendium-xml\",\n",
    "    temperature=0.2,\n",
    "    \n",
    "    # Optional parameters (using defaults)\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"\\nResults saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd828d",
   "metadata": {},
   "source": [
    "## Example: Different Configuration\n",
    "\n",
    "You can run multiple evaluations with different configurations to compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e97846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with different parameters (uncomment to run)\n",
    "\n",
    "# csv_path = generate_evaluation_results(\n",
    "#     llm=\"openai/gpt-oss-120b\",\n",
    "#     embedding_model=\"openai/octen-embedding-8b\",\n",
    "#     input_data_description=\"XML Kompendium 2023, larger chunks (8000 chars) with 400 overlap\",\n",
    "#     chunk_size=8000,\n",
    "#     chunk_overlap=400,\n",
    "#     top_k=3,  # Fewer but larger chunks\n",
    "#     output_name=\"gpt-oss-120b_kompendium-xml-large-chunks\",\n",
    "#     temperature=0.1,  # Lower temperature for more deterministic outputs\n",
    "#     seed=123,  # Different seed\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3aefa6",
   "metadata": {},
   "source": [
    "## Output Files\n",
    "\n",
    "The function generates two files in `data/results/`:\n",
    "\n",
    "1. **CSV file** (`{output_name}.csv`): Contains all evaluation data with columns:\n",
    "   - `Frage` - Original question\n",
    "   - `Antwort` - Ground truth answer\n",
    "   - `Fundstellen` - Ground truth context references\n",
    "   - `Generierte Antwort` - LLM-generated answer\n",
    "   - `Ermittelte Fundstellen` - Retrieved context chunks\n",
    "   - `context_precision` - RAGAS metric\n",
    "   - `context_recall` - RAGAS metric\n",
    "   - `faithfulness` - RAGAS metric\n",
    "   - `answer_correctness` - RAGAS metric\n",
    "\n",
    "2. **README file** (`{output_name}.md`): Documentation including:\n",
    "   - Input data description\n",
    "   - Model configuration\n",
    "   - Preprocessing parameters\n",
    "   - RAGAS metrics summary (avg, min, max, std dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c205c7",
   "metadata": {},
   "source": [
    "## View Generated Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf01e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Read and display the generated CSV\n",
    "results_dir = PROJECT_ROOT / \"data\" / \"results\"\n",
    "\n",
    "# List all result files\n",
    "print(\"Available result files:\")\n",
    "for f in sorted(results_dir.glob(\"*\")):\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e152c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preview a specific result (replace with your output_name)\n",
    "result_name = \"gpt-oss-120b_kompendium-xml\"\n",
    "\n",
    "csv_file = results_dir / f\"{result_name}.csv\"\n",
    "if csv_file.exists():\n",
    "    df = pd.read_csv(csv_file, sep=\";\", encoding=\"utf-8-sig\")\n",
    "    print(f\"Loaded {len(df)} results\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(f\"File not found: {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b784adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the README\n",
    "readme_file = results_dir / f\"{result_name}.md\"\n",
    "if readme_file.exists():\n",
    "    display(Markdown(readme_file.read_text(encoding=\"utf-8\")))\n",
    "else:\n",
    "    print(f\"File not found: {readme_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b849810d",
   "metadata": {},
   "source": [
    "## Metrics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2974587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display metrics summary\n",
    "if 'df' in dir() and df is not None:\n",
    "    metrics = [\"context_precision\", \"context_recall\", \"faithfulness\", \"answer_correctness\"]\n",
    "    \n",
    "    summary = df[metrics].agg([\"mean\", \"min\", \"max\", \"std\"]).T\n",
    "    summary.columns = [\"Average\", \"Min\", \"Max\", \"Std Dev\"]\n",
    "    \n",
    "    # Convert to percentages\n",
    "    summary = summary * 100\n",
    "    summary = summary.round(1)\n",
    "    \n",
    "    display(Markdown(\"### RAGAS Metrics Summary (Percentages)\"))\n",
    "    display(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pilotprojekt-grundschutzki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
